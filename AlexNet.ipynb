{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import cifar10\n",
    "from cifar10 import img_size, num_channels, num_classes\n",
    "img_size_cropped = 24\n",
    "img_size_cropped = 24\n",
    "session = tf.Session()\n",
    "save_dir = 'checkpoints_alex/'\n",
    "save_path = os.path.join(save_dir, 'cifar10_cnn')\n",
    "cifar10.maybe_download_and_extract()\n",
    "images_train, cls_train, labels_train = cifar10.load_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre_process_image(image, training):\n",
    "    # This function takes a single image as input,\n",
    "    # and a boolean whether to build the training or testing graph.\n",
    "    \n",
    "    if training:\n",
    "        # For training, add the following to the TensorFlow graph.\n",
    "\n",
    "        # Randomly crop the input image.\n",
    "        image = tf.random_crop(image, size=[img_size_cropped, img_size_cropped, num_channels])\n",
    "\n",
    "        # Randomly flip the image horizontally.\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        \n",
    "        # Randomly adjust hue, contrast and saturation.\n",
    "        image = tf.image.random_hue(image, max_delta=0.05)\n",
    "        image = tf.image.random_contrast(image, lower=0.3, upper=1.0)\n",
    "        image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "        image = tf.image.random_saturation(image, lower=0.0, upper=2.0)\n",
    "\n",
    "        # Some of these functions may overflow and result in pixel\n",
    "        # values beyond the [0, 1] range. It is unclear from the\n",
    "        # documentation of TensorFlow whether this is\n",
    "        # intended. A simple solution is to limit the range.\n",
    "\n",
    "        # Limit the image pixels between [0, 1] in case of overflow.\n",
    "        image = tf.minimum(image, 1.0)\n",
    "        image = tf.maximum(image, 0.0)\n",
    "    else:\n",
    "        # For training, add the following to the TensorFlow graph.\n",
    "\n",
    "        # Crop the input image around the centre so it is the same\n",
    "        # size as images that are randomly cropped during training.\n",
    "        image = tf.image.resize_image_with_crop_or_pad(image,\n",
    "                                                       target_height=img_size_cropped,\n",
    "                                                       target_width=img_size_cropped)\n",
    "\n",
    "    return image\n",
    "\n",
    "def pre_process(images, training):\n",
    "    # Use TensorFlow to loop over all the input images and call\n",
    "    # the function above which takes a single image as input.\n",
    "    images = tf.map_fn(lambda image: pre_process_image(image, training), images)\n",
    "\n",
    "    return images\n",
    "\n",
    "def random_batch(images_train, labels_train, size):\n",
    "    # Number of images in the training-set.\n",
    "    num_images = len(images_train)\n",
    "\n",
    "    # Create a random index.\n",
    "    idx = np.random.choice(num_images,\n",
    "                           size=size,\n",
    "                           replace=False)\n",
    "\n",
    "    # Use the random index to select random images and labels.\n",
    "    x_batch = images_train[idx, :, :, :]\n",
    "    y_batch = labels_train[idx, :]\n",
    "\n",
    "    return x_batch, y_batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea of 'two eyes' implemented in NN as 'groups'\n",
    "When 'groups' is equal to 2 - the filters and feature maps are considered separately from each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def conv(x, out, name, groups, kernel_size=3, stride_x=1, stride_y=1, padding='SAME'):\n",
    "    with tf.name_scope(name):\n",
    "        depth = x.get_shape().as_list()[-1] // groups\n",
    "        convolve = lambda input_, filter_: \\\n",
    "            tf.nn.conv2d(input_, filter_, [1, stride_x, stride_y, 1], padding)\n",
    "        W = weight_variable(shape=[kernel_size, kernel_size, depth, out], name='W')\n",
    "        b = bias_variable((out,), name=\"b\")\n",
    "        if groups == 1:\n",
    "            conv = convolve(x, W)\n",
    "        else:\n",
    "            x_groups = tf.split(axis=3, num_or_size_splits=groups, value=x)\n",
    "            w_groups = tf.split(axis=3, num_or_size_splits=groups, value=W)\n",
    "            conv = tf.concat(axis=3, values=[convolve(i, k) for i, k in zip(x_groups, w_groups)])\n",
    "\n",
    "        return tf.nn.relu(tf.nn.bias_add(conv, b), name=name)\n",
    "def dropout(x, keep_prob=0.5):\n",
    "    return tf.nn.dropout(x, keep_prob)\n",
    "\n",
    "def weight_variable(shape, name):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "    initial = tf.constant(0.3, shape=shape)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "def full(x, n_out, name, activ=tf.nn.relu):\n",
    "    with tf.name_scope(name):\n",
    "        flattened = tf.reshape(x, [-1, int(np.prod(x.shape[1:]))])\n",
    "        return tf.layers.dense(flattened, n_out, activation=activ)\n",
    "\n",
    "def max_pool(x, name, kernel_size=3, stride_x=2, stride_y=2, padding='VALID'):\n",
    "    return tf.nn.max_pool(x, ksize=[1, kernel_size, kernel_size, 1],\n",
    "                         strides=[1, stride_x, stride_y, 1],\n",
    "                         padding=padding, name=name)\n",
    "\n",
    "def lrn(x, *, radius=2, alpha=1e-4, bias=2, beta=0.75, name):\n",
    "    return tf.nn.lrn(x, depth_radius=radius, bias=bias, alpha=alpha, beta=beta, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class AlexNet:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 32\n",
    "        self.save_path = save_path\n",
    "        self.create_placeholder()\n",
    "        self.create_model()\n",
    "        self.create_fields()\n",
    "     \n",
    "    def create_placeholder(self):\n",
    "        self.images = tf.placeholder(shape=[self.batch_size, img_size, img_size, num_channels], dtype=tf.float32, name='img')\n",
    "        self.x = pre_process(images=self.images, training=True)\n",
    "        self.y_true = tf.placeholder(shape=[self.batch_size, num_classes], dtype=tf.int64, name='y_true')\n",
    "        self.y_true_cls = tf.argmax(self.y_true, axis=1)\n",
    "\n",
    "    def create_model(self):\n",
    "        with tf.name_scope(\"layer1\"):\n",
    "            conv1 = conv(x=self.x, groups=1, kernel_size=7, out=64, name='conv1')\n",
    "            lrn1 = lrn(conv1, name=\"lrn1\")\n",
    "            pool1 = max_pool(lrn1, name ='pool2')\n",
    "        \n",
    "        with tf.name_scope(\"layer12\"):\n",
    "            conv2 = conv(x=lrn1, groups=2, kernel_size=5, out=96, name='conv2')\n",
    "            pool2 =max_pool(x=conv2, name ='pool2')\n",
    "            lrn2 = lrn(pool2, name=\"lrn2\")\n",
    "       \n",
    "        \n",
    "        with tf.name_scope(\"layer3-5\"):\n",
    "            conv3 = conv(x=lrn2, groups=1, out=192, name='conv3')\n",
    "            conv4 = conv(conv3, groups=2, out=192, name = 'conv4')\n",
    "            conv5 = conv(conv4, groups=2, out=128, name = 'conv5')\n",
    "            pool5 = max_pool(x=conv5, name = 'pool5')\n",
    "\n",
    "        with tf.name_scope(\"layer6\"):\n",
    "            full6 = full(pool5, 128, name='full6')\n",
    "        \n",
    "        with tf.name_scope(\"layer7\"):\n",
    "            full7 = full(full6, 512, name = 'full7')\n",
    "        \n",
    "        with tf.name_scope(\"layer8\"):\n",
    "            full8 = full(full7, num_classes, activ=None, name='full8')\n",
    "        \n",
    "        self.logits = full8\n",
    "        print(\"Here\")\n",
    "\n",
    "    def create_fields(self):\n",
    "        self.y_pred_cls = tf.argmax(tf.nn.softmax(self.logits), axis=1)\n",
    "        self.global_step = tf.Variable(initial_value=0, name='global_step', trainable=False)\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=self.y_true, logits = self.logits))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(loss, global_step=self.global_step)\n",
    "        self.saver = tf.train.Saver()\n",
    "        correct_prediction = tf.equal(self.y_pred_cls, self.y_true_cls)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "    def load_model(self, session):\n",
    "        try:\n",
    "            print(\"Trying to restore last checkpoint ...\")\n",
    "            last_chk_path = tf.train.latest_checkpoint(checkpoint_dir=self.save_dir)\n",
    "            self.saver.restore(session, save_path=last_chk_path)\n",
    "            print(\"Restored checkpoint from:\", last_chk_path)\n",
    "        except:\n",
    "            print(\"Failed to restore checkpoint. Initializing variablies.\")\n",
    "            session.run(tf.global_variables_initializer())\n",
    "\n",
    "    def train(self, num_iterations, y_true, images):\n",
    "        with tf.Session() as session:\n",
    "            self.load_model(session)\n",
    "            tf.summary.FileWriter('graphs', session.graph)\n",
    "\n",
    "            for i in range(num_iterations):\n",
    "                x_batch, y_true_batch = random_batch(images, y_true, self.batch_size)\n",
    "\n",
    "                feed_dict_train = {self.images: x_batch, self.y_true: y_true_batch}\n",
    "\n",
    "                i_global, _ = session.run([self.global_step, self.optimizer],\n",
    "                                          feed_dict=feed_dict_train)\n",
    "\n",
    "                if (i_global % 100 == 0) or (i == num_iterations - 1):\n",
    "                    batch_acc = session.run(self.accuracy,\n",
    "                                            feed_dict=feed_dict_train)\n",
    "                    msg = \"Global Step: {0:>6}, Training Batch Accuracy: {1:>6.1%}\"\n",
    "                    print(msg.format(i_global, batch_acc))\n",
    "\n",
    "                if (i_global % 1000 == 0) or (i == num_iterations - 1):\n",
    "                    self.saver.save(session,\n",
    "                               save_path=self.save_path,\n",
    "                               global_step=self.global_step)\n",
    "\n",
    "                    print(\"Saved checkpoint.\") \n",
    "    def test(self, images, labels, cls_true):\n",
    "        num_images = len(images)\n",
    "        cls_pred = np.zeros(shape=num_images, dtype=np.int)\n",
    "\n",
    "        for i in range(0, n_images, self.batch_size):\n",
    "            j = min(i + self.batch_size, num_images)\n",
    "            feed_dict = {self.images: images[i:j, :], self.y_true: labels[i:j, :]}\n",
    "            cls_pred[i:j] = session.run(self.y_pred_cls, feed_dict)\n",
    "        correct = (cls_true == cls_pred)\n",
    "        return cls_pred, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here\n",
      "Trying to restore last checkpoint ...\n",
      "Failed to restore checkpoint. Initializing variablies.\n",
      "Global Step:    100, Training Batch Accuracy:  18.8%\n",
      "Global Step:    200, Training Batch Accuracy:  12.5%\n",
      "Global Step:    300, Training Batch Accuracy:  37.5%\n",
      "Global Step:    400, Training Batch Accuracy:  28.1%\n",
      "Global Step:    500, Training Batch Accuracy:  34.4%\n",
      "Global Step:    600, Training Batch Accuracy:  37.5%\n",
      "Global Step:    700, Training Batch Accuracy:  28.1%\n",
      "Global Step:    800, Training Batch Accuracy:  28.1%\n",
      "Global Step:    900, Training Batch Accuracy:  37.5%\n",
      "Global Step:   1000, Training Batch Accuracy:  40.6%\n",
      "Saved checkpoint.\n",
      "Global Step:   1100, Training Batch Accuracy:  37.5%\n",
      "Global Step:   1200, Training Batch Accuracy:  28.1%\n",
      "Global Step:   1300, Training Batch Accuracy:  53.1%\n",
      "Global Step:   1400, Training Batch Accuracy:  40.6%\n",
      "Global Step:   1500, Training Batch Accuracy:  21.9%\n",
      "Global Step:   1600, Training Batch Accuracy:  43.8%\n",
      "Global Step:   1700, Training Batch Accuracy:  31.2%\n",
      "Global Step:   1800, Training Batch Accuracy:  25.0%\n",
      "Global Step:   1900, Training Batch Accuracy:  37.5%\n",
      "Global Step:   2000, Training Batch Accuracy:  37.5%\n",
      "Saved checkpoint.\n",
      "Global Step:   2100, Training Batch Accuracy:  46.9%\n",
      "Global Step:   2200, Training Batch Accuracy:  46.9%\n",
      "Global Step:   2300, Training Batch Accuracy:  56.2%\n",
      "Global Step:   2400, Training Batch Accuracy:  31.2%\n",
      "Global Step:   2500, Training Batch Accuracy:  46.9%\n",
      "Global Step:   2600, Training Batch Accuracy:  50.0%\n",
      "Global Step:   2700, Training Batch Accuracy:  15.6%\n",
      "Global Step:   2800, Training Batch Accuracy:  40.6%\n",
      "Global Step:   2900, Training Batch Accuracy:  34.4%\n",
      "Global Step:   3000, Training Batch Accuracy:  28.1%\n",
      "Saved checkpoint.\n",
      "Global Step:   3100, Training Batch Accuracy:  43.8%\n",
      "Global Step:   3200, Training Batch Accuracy:  56.2%\n",
      "Global Step:   3300, Training Batch Accuracy:  18.8%\n",
      "Global Step:   3400, Training Batch Accuracy:  25.0%\n",
      "Global Step:   3500, Training Batch Accuracy:  50.0%\n",
      "Global Step:   3600, Training Batch Accuracy:  37.5%\n",
      "Global Step:   3700, Training Batch Accuracy:  31.2%\n",
      "Global Step:   3800, Training Batch Accuracy:  43.8%\n",
      "Global Step:   3900, Training Batch Accuracy:  34.4%\n",
      "Global Step:   4000, Training Batch Accuracy:  43.8%\n",
      "Saved checkpoint.\n",
      "Global Step:   4100, Training Batch Accuracy:  46.9%\n",
      "Global Step:   4200, Training Batch Accuracy:  50.0%\n",
      "Global Step:   4300, Training Batch Accuracy:  43.8%\n",
      "Global Step:   4400, Training Batch Accuracy:  31.2%\n",
      "Global Step:   4500, Training Batch Accuracy:  28.1%\n",
      "Global Step:   4600, Training Batch Accuracy:  56.2%\n",
      "Global Step:   4700, Training Batch Accuracy:  50.0%\n",
      "Global Step:   4800, Training Batch Accuracy:  50.0%\n",
      "Global Step:   4900, Training Batch Accuracy:  37.5%\n",
      "Global Step:   5000, Training Batch Accuracy:  50.0%\n",
      "Saved checkpoint.\n",
      "Global Step:   5100, Training Batch Accuracy:  46.9%\n"
     ]
    }
   ],
   "source": [
    "alex = AlexNet()\n",
    "alex.train(100000, labels_train, images_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter2_Python_2",
   "language": "python",
   "name": "jupyter2_python_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
