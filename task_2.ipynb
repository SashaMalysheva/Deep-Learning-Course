{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Restore FashionNet architecture using tf-graph in ./graph and this code sample\n",
    "# dataset available at https://github.com/zalandoresearch/fashion-mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting fashion-mnist/data/fashion/train-images-idx3-ubyte.gz\n",
      "Extracting fashion-mnist/data/fashion/train-labels-idx1-ubyte.gz\n",
      "Extracting fashion-mnist/data/fashion/t10k-images-idx3-ubyte.gz\n",
      "Extracting fashion-mnist/data/fashion/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "from IPython.display import Image\n",
    "\n",
    "mnist = input_data.read_data_sets('fashion-mnist/data/fashion', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](fashion-mnist/visualization/zalando-mnist-sprite.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape, name):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W, name=None):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1],\n",
    "                        padding='SAME', name=name)\n",
    "\n",
    "def max_pool_2x2(x, name=None):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1],\n",
    "                          padding='SAME', name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FasionNet:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def _create_placeholders(self):\n",
    "        with tf.name_scope(\"data\"):\n",
    "            self.x = tf.placeholder(tf.float32, shape=(None, 784), name=\"X\")\n",
    "            self.y_ = tf.placeholder(tf.float32, shape=(None, 10), name=\"y\")\n",
    "    \n",
    "    def _create_layer1(self):\n",
    "        with tf.name_scope(\"layer1\"):\n",
    "            W_conv1 = weight_variable((5, 5, 1, 32), name=\"W_conv1\")\n",
    "            b_conv1 = bias_variable((32,), name=\"b_conv1\")\n",
    "            x_image = tf.reshape(self.x, [-1, 28, 28, 1], name=\"x_image\")\n",
    "            h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1, name=\"h_conv1\")\n",
    "            self.h_pool1 = max_pool_2x2(h_conv1, name=\"h_pool1\")\n",
    "    \n",
    "    def _create_layer2(self):\n",
    "        with tf.name_scope(\"layer2\"):\n",
    "            W_conv2 = weight_variable((5, 5, 32, 64), name=\"W_conv2\")\n",
    "            b_conv2 = bias_variable((64,), name=\"b_conv2\")\n",
    "\n",
    "            h_conv2 = tf.nn.relu(conv2d(self.h_pool1, W_conv2) + b_conv2, name=\"h_conv2\")\n",
    "            h_pool2 = max_pool_2x2(h_conv2, name=\"h_pool2\")\n",
    "\n",
    "            W_fc1 = weight_variable((3136, 1024), name=\"W_fc1\")\n",
    "            b_fc1 = bias_variable((1024, ), name=\"b_fc1\")\n",
    "\n",
    "            h_pool2_flat = tf.reshape(h_pool2, [-1, 3136], name=\"h_pool2_flat\")\n",
    "            h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1, name=\"h_fc1\")\n",
    "\n",
    "            self.keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "            h_fc1_drop = tf.nn.dropout(h_fc1, self.keep_prob, name=\"h_fc1_drop\")\n",
    "\n",
    "            W_fc2 = weight_variable(shape=(1024, 10), name=\"W_fc2\")\n",
    "            b_fc2 = bias_variable(shape=(10,), name=\"b_fc2\")\n",
    "\n",
    "            self.y_conv = tf.add(tf.matmul(h_fc1_drop, W_fc2), b_fc2, name='y_conv')\n",
    "            \n",
    "    \n",
    "    def _create_loss(self):\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            self.cross_entropy = tf.reduce_mean(\n",
    "                tf.nn.softmax_cross_entropy_with_logits(labels=self.y_, logits=self.y_conv))\n",
    "            \n",
    "    def _create_optimizer(self):\n",
    "        with tf.name_scope(\"optimizer\"):\n",
    "            self.train_step = tf.train.AdamOptimizer(1e-4).minimize(self.cross_entropy)\n",
    "            \n",
    "    def _create_summaries(self):\n",
    "        with tf.name_scope(\"summaries\"):\n",
    "            tf.summary.scalar('loss', self.cross_entropy)\n",
    "            correct_prediction = tf.equal(tf.argmax(self.y_conv, 1), tf.argmax(self.y_, 1))\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "            \n",
    "            self.summary = tf.summary.merge_all()\n",
    "            saver = tf.train.Saver()\n",
    "            \n",
    "    def build_graph(self):\n",
    "        self._create_placeholders()\n",
    "        self._create_layer1()\n",
    "        self._create_layer2()\n",
    "        self._create_loss()\n",
    "        self._create_optimizer()\n",
    "        self._create_summaries()\n",
    "    \n",
    "    def train_model(self):\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            summary_writer = tf.summary.FileWriter('graphs', sess.graph)\n",
    "            for i in range(800):\n",
    "                batch = mnist.train.next_batch(50)\n",
    "                if i % 100 == 0:\n",
    "                    train_accuracy = self.accuracy.eval(feed_dict={self.x: batch[0], self.y_: batch[1], self.keep_prob: 1.0})\n",
    "                    print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "                    \n",
    "                _, summary_str = sess.run([self.train_step, self.summary], \n",
    "                                          feed_dict={self.x: batch[0], self.y_: batch[1], self.keep_prob: 0.5})\n",
    "                \n",
    "                summary_writer.add_summary(summary_str, i)\n",
    "\n",
    "            print('test accuracy {}'.format(self.accuracy.eval(feed_dict={self.x: mnist.test.images, self.y_: mnist.test.labels, self.keep_prob: 1})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.04\n",
      "step 100, training accuracy 0.88\n",
      "step 200, training accuracy 0.94\n",
      "step 300, training accuracy 0.86\n",
      "step 400, training accuracy 1\n",
      "step 500, training accuracy 0.9\n",
      "step 600, training accuracy 1\n",
      "step 700, training accuracy 0.96\n"
     ]
    }
   ],
   "source": [
    "fn = FasionNet()\n",
    "fn.build_graph()\n",
    "fn.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
